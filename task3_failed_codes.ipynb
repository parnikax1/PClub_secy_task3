{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Used Model MTCNN for face detection and cropping\n",
    "\n",
    "after i read a documention about the study of gender detection of masked faces, i came across this model MTCNN which is supposed to have a fairly higher cacuracy. I implemented the model and it did work but the model was too slow cropping images at a rate of 0.4ms/image. After waiting for 5 hours approx, i got 18k cropped images saved in a separate folder called haarcasscade which i have uploaded in the repo as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to process each image\n",
    "def process_image(filename, dataset_path, output_path, image_size=(96, 96)):\n",
    "    image_path = os.path.join(dataset_path, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    detector = MTCNN()\n",
    "    \n",
    "    # Resize the image\n",
    "    image = cv2.resize(image, image_size)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    result = detector.detect_faces(image)\n",
    "    if len(result) == 0:\n",
    "        print(f'No face detected on {image_path}')\n",
    "        return None, None\n",
    "    \n",
    "    # For this example, we will use the first detected face\n",
    "    face = result[0]\n",
    "    bounding_box = face['box']\n",
    "    \n",
    "    x, y, width, height = bounding_box\n",
    "    x2, y2 = x + width, y + height\n",
    "    \n",
    "    # Crop the face from the image\n",
    "    cropped_face = image[y:y2, x:x2]\n",
    "    \n",
    "    # Extract the label from the filename (assuming the format is age_gender_race_date.jpg)\n",
    "    label = filename.split('_')[1]  # Adjust based on the required label (age/gender/race)\n",
    "    \n",
    "    # Ensure output_path has a valid image file extension and save the cropped face\n",
    "    output_file = os.path.join(output_path, f\"{label}_{os.path.splitext(filename)[0]}.jpg\")\n",
    "    cv2.imwrite(output_file, cropped_face)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Function to handle parallel processing\n",
    "def process_images_in_parallel(dataset_path, output_path, max_workers=4):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    filenames = [f for f in os.listdir(dataset_path) if f.endswith(\".jpg\")]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_image, filename, dataset_path, output_path) for filename in filenames]\n",
    "        \n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result[0] is not None:\n",
    "                data.append(result[0])\n",
    "                labels.append(result[1])\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Define the paths\n",
    "dataset_path = r'D:\\ESC4\\pclub_task3\\dataset'\n",
    "output_path = r'D:\\ESC4\\pclub_task3\\haarcascade'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Process images and labels\n",
    "data, labels = process_images_in_parallel(dataset_path, output_path)\n",
    "\n",
    "# Convert the data and labels to NumPy arrays\n",
    "data = np.array(data, dtype=np.float32) / 255.0\n",
    "labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of the datasets\n",
    "print(f\"Training data shape: {trainX.shape}\")\n",
    "print(f\"Testing data shape: {testX.shape}\")\n",
    "print(f\"Training labels shape: {trainY.shape}\")\n",
    "print(f\"Testing labels shape: {testY.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Double Checking of faces detected in the cropped Images\n",
    "\n",
    "I had this folder of cropped images and on scimming through it i found weirdly cropped images in which face wasn't fully present. So i decided to implement another model i.e. harcascade to check on the detected images. I got a probability of the facebein detected and if the probability was less than 0.5, i did os.remove(file) which led ot made dataset of cropped images being reduced from 18k to 8k in 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_filter_faces(input_folder, haar_cascade_path):\n",
    "    face_cascade = cv2.CascadeClassifier(haar_cascade_path)\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    c=0\n",
    "    for img_name in os.listdir(input_folder):\n",
    "        # print(img_name)\n",
    "        img_path = os.path.join(input_folder, img_name)\n",
    "        # print(img_path)\n",
    "        # if not os.path.isdir(img_path):\n",
    "        #     continue\n",
    "        \n",
    "        # output_img_path = os.path.join(output_folder, img)\n",
    "        # os.makedirs(output_img_path, exist_ok=True)\n",
    "        \n",
    "        # for image_name in os.listdir(img_path):\n",
    "        # print(img_name)\n",
    "        # image_path = os.path.join(img_path, image_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        label=int(img_name.split('_')[1])\n",
    "        # print(image_name)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        if len(faces) == 0:\n",
    "            os.remove(img_path)  # Delete the image if no face is detected\n",
    "            print(f\"No face detected in {img_path}, deleted.\")\n",
    "            c+=1\n",
    "            continue\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Crop the top 50% of the detected face\n",
    "            top_half_face = image[y:y + h//2, x:x + w]\n",
    "            top_half_face=cv2.resize(top_half_face, (96,96))\n",
    "            images.append(top_half_face)\n",
    "            labels.append(label)\n",
    "            # print(label)\n",
    "            # cropped_image_name = f\"cropped_{image_name}\"\n",
    "            # cropped_image_path = os.path.join(output_img_path, cropped_image_name)\n",
    "            # cv2.imwrite(cropped_image_path, top_half_face)\n",
    "            # print(f\"Saved cropped face to {cropped_image_path}\")\n",
    "    images=np.array(images)\n",
    "    labels=np.array(labels)\n",
    "    return images, labels, c\n",
    "\n",
    "input_folder = r\"D:\\ESC4\\pclub_task3\\dataset\"\n",
    "output_folder = r\"D:\\ESC4\\pclub_task3\\haarcascade\"\n",
    "haar_cascade_path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "images, labels, c=detect_and_filter_faces(input_folder, haar_cascade_path)\n",
    "print(c)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
